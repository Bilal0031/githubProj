{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uB1FEy0ZD7wSOeKBCbumnsZtckzIn0fO",
      "authorship_tag": "ABX9TyP1yXFXeFrBydQuFw5kuF4N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bilal0031/githubProj/blob/master/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjnt78GrmUJL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Sa3bNp9ooXqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "gNMsjlb4ocWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "cy71xm_CogKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "P8_hsAkloyfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "mObxlwwLpAIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "a1E-MLabpNn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_input_ids = np.zeros((len(df), 256))\n",
        "X_attn_masks = np.zeros((len(df), 256))\n"
      ],
      "metadata": {
        "id": "IT3fmkDhpWc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_dataset(df, ids, masks, tokenizer):\n",
        "    for i, text in tqdm(enumerate(df['Phrase'])):\n",
        "        tokenized_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=256, \n",
        "            truncation=True, \n",
        "            padding='max_length', \n",
        "            add_special_tokens=True,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "        ids[i, :] = tokenized_text.input_ids\n",
        "        masks[i, :] = tokenized_text.attention_mask\n",
        "    return ids, masks"
      ],
      "metadata": {
        "id": "dO2ZGIrupro7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_input_ids, X_attn_masks = preprocessing_dataset(df, X_input_ids, X_attn_masks, tokenizer)"
      ],
      "metadata": {
        "id": "va57JC5Op77t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.zeros((len(df), 5))"
      ],
      "metadata": {
        "id": "hXiAIF76qjXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "JlHL8r69qrp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(156059, 5)"
      ],
      "metadata": {
        "id": "4oc5EzxPqzpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[np.arange(len(df)), df['Sentiment'].values]"
      ],
      "metadata": {
        "id": "Heh1yrrfq7ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))"
      ],
      "metadata": {
        "id": "coYEPvdfq_Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(1)"
      ],
      "metadata": {
        "id": "Y2OzE6USrGYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attn_masks\n",
        "    }, labels"
      ],
      "metadata": {
        "id": "LATMHUpFrK_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(SentimentDatasetMapFunction)"
      ],
      "metadata": {
        "id": "P_wmVOB5rTHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) \n"
      ],
      "metadata": {
        "id": "TytuSfBRrXhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.8\n",
        "train_size = int((len(df)//16)*p)"
      ],
      "metadata": {
        "id": "aBKEZjccrgiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = dataset.take(train_size)\n",
        "validation_dataset = dataset.skip(train_size)\n"
      ],
      "metadata": {
        "id": "AJRqFbworlHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertModel"
      ],
      "metadata": {
        "id": "XOER-pQProej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "jvcEjKRlrvUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n"
      ],
      "metadata": {
        "id": "F2mCnuAnr0zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')"
      ],
      "metadata": {
        "id": "h7a3Ng7Qr3Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1]"
      ],
      "metadata": {
        "id": "p3xPdFCJr-Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)"
      ],
      "metadata": {
        "id": "K4iKXHdDsCA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = tf.keras.layers.Dense(5, activation='softmax', name='output_layer')(intermediate_layer) "
      ],
      "metadata": {
        "id": "Pp4c4XW9sFvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)"
      ],
      "metadata": {
        "id": "VydCszRVsNvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.summary()"
      ],
      "metadata": {
        "id": "k-Fuij0fsVzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n"
      ],
      "metadata": {
        "id": "vd_PWzV6sajE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = tf.keras.losses.CategoricalCrossentropy()\n"
      ],
      "metadata": {
        "id": "WjFoMcjBsb6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n"
      ],
      "metadata": {
        "id": "pTpE_SYSsgxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])\n"
      ],
      "metadata": {
        "id": "BWBQdHjKsm4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_training = sentiment_model.fit(\n",
        "    training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=2\n",
        ")"
      ],
      "metadata": {
        "id": "qF4kOKDgsvS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "P-R9c3hNY-eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(input_text, tokenizer):\n",
        "    token = tokenizer.encode_plus(\n",
        "        input_text,\n",
        "        max_length=256, \n",
        "        truncation=True, \n",
        "        padding='max_length', \n",
        "        add_special_tokens=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "    return {\n",
        "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
        "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "fZb0DSm6Z56j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model, processed_data, classes=['Negative', 'A bit negative', 'Neutral', 'A bit positive', 'Positive']):\n",
        "    probs = sentiment_model.predict(processed_data)[0]\n",
        "    return classes[np.argmax(probs)]"
      ],
      "metadata": {
        "id": "VC_cX1LFZ_jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = input('Input a review here:')\n",
        "processed_data = prepare_data(input_text, tokenizer)\n",
        "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
        "print(f\"Classification results: {result}\")"
      ],
      "metadata": {
        "id": "Bigxw037QyFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}